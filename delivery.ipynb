{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"text-align:center;\">Mass Shootings in the USA</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"text-align:center;\">Laia Mogas i Pau Mateo</p>\n",
    "<p style=\"text-align:center;\">Information Visualization - GCED</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Obtaining data\n",
    "The main data sources we used in this project are:\n",
    "- https://www2.census.gov/\n",
    "- https://www.gunviolencearchive.org/reports\n",
    "\n",
    "From theese sources we obtain the following datasets:\n",
    "- Mass shootings (january 2014 to september 2024)\n",
    "- School incidents (january 2022 to 2024)\n",
    "- County population\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing and data cleaning - County Population\n",
    "We obtained the conty popultion data with two separate csv files: one correspondig to the years 2014-2019, an another one for 2020 and later. These datasets contained a lot of information, but we only needed the population estimate foer each county every year, so we eliminated the unnecesary columns. We merged these two datasets with pytohn pandas. Then noticed that the state Connecticut had a county redistribuition in 2020, so we decided to keep the latest cofniguration of counties and estimate uniformly the population of those counties for years before 2020. The code we used for this preprocessing is the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "pop2010_20 = pd.read_csv('datasets/co-est2010-2020_alldata.csv', encoding='latin1')\n",
    "pop2020_23 = pd.read_csv('datasets/co-est2020-2023_alldata.csv', encoding='latin1')\n",
    "\n",
    "########## column projection ##########\n",
    "columns2010 = ['STATE', 'COUNTY','STNAME','CTYNAME']\n",
    "columns2010.extend(['POPESTIMATE201'+str(i) for i in range(10)])\n",
    "columns2020 = ['STATE', 'COUNTY','STNAME','CTYNAME']\n",
    "columns2020.extend(['POPESTIMATE202'+str(i) for i in range(4)])\n",
    "\n",
    "pop2010_20['FIPS'] = pop2010_20.apply(lambda row: f\"{int(row['STATE']):02d}{int(row['COUNTY']):03d}\", axis=1)\n",
    "pop2020_23['FIPS'] = pop2020_23.apply(lambda row: f\"{int(row['STATE']):02d}{int(row['COUNTY']):03d}\", axis=1)\n",
    "\n",
    "\n",
    "##########     merge     ##########\n",
    "popComplete = pd.merge(pop2010_20[columns2010], pop2020_23[columns2020], on=['STATE', 'COUNTY'])\n",
    "\n",
    "popComplete['STATE'] = popComplete['STATE'].astype(str)\n",
    "popComplete['COUNTY'] = popComplete['COUNTY'].astype(str)\n",
    "\n",
    "\n",
    "########## obraining FIPS ##########\n",
    "popComplete['FIPS'] = popComplete.apply(lambda row: f\"{int(row['STATE']):02d}{int(row['COUNTY']):03d}\", axis=1)\n",
    "popComplete['STNAME'] = popComplete['STNAME_x']\n",
    "popComplete['CTYNAME'] = popComplete['CTYNAME_x']\n",
    "\n",
    "########## ordering columns ##########\n",
    "new_cols_order = ['STNAME', 'CTYNAME', 'FIPS', 'STATE', 'COUNTY'] + ['POPESTIMATE20'+f'{i:02d}' for i in range(14,24)]\n",
    "popComplete = popComplete[new_cols_order]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['09001', '09003', '09005', '09007', '09009', '09011', '09013', '09015']\n",
      "['09110', '09120', '09130', '09140', '09150', '09160', '09170', '09180', '09190']\n"
     ]
    }
   ],
   "source": [
    "##### checking changed counties #####\n",
    "\n",
    "l1 = []\n",
    "for c in pop2010_20['FIPS']:\n",
    "    if c not in popComplete['FIPS'].values:\n",
    "        l1.append(c)\n",
    "\n",
    "l2 = []\n",
    "for c in pop2020_23['FIPS']:\n",
    "    if c not in popComplete['FIPS'].values:\n",
    "        l2.append(c)\n",
    "\n",
    "print(l1)\n",
    "print(l2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### dealing with state '09' (connecticut) ######\n",
    "from collections import defaultdict\n",
    "\n",
    "fips_connecticut = pop2020_23[pop2020_23['STATE']==9]['FIPS'].values\n",
    "N = len(fips_connecticut)\n",
    "\n",
    "totalpop = defaultdict()\n",
    "\n",
    "\n",
    "for i in range(14,24):\n",
    "    year = 'POPESTIMATE20'+ f'{i:02d}'\n",
    "    #calculate total population in state '09' in this year\n",
    "    if i < 20:\n",
    "        totalpop[year] = sum(pop2010_20[pop2010_20['STATE'] == 9][year].values)\n",
    "    else:\n",
    "        totalpop[year] = sum(pop2020_23[pop2020_23['STATE'] == 9][year].values)\n",
    "\n",
    "\n",
    "for fips in fips_connecticut:\n",
    "    new_row = pd.Series({\n",
    "        'STNAME': 'Connecticut', \n",
    "        'CTYNAME': 'connecticut_county_unknown',\n",
    "        'FIPS': fips, \n",
    "        'STATE': 9, \n",
    "        'COUNTY': fips[2:],\n",
    "        'POPESTIMATE2014': totalpop['POPESTIMATE2014'] / N,\n",
    "        'POPESTIMATE2015': totalpop['POPESTIMATE2015'] / N,\n",
    "        'POPESTIMATE2016': totalpop['POPESTIMATE2016'] / N,\n",
    "        'POPESTIMATE2017': totalpop['POPESTIMATE2017'] / N,\n",
    "        'POPESTIMATE2018': totalpop['POPESTIMATE2018'] / N,\n",
    "        'POPESTIMATE2019': totalpop['POPESTIMATE2019'] / N,\n",
    "        'POPESTIMATE2020': totalpop['POPESTIMATE2020'] / N,\n",
    "        'POPESTIMATE2021': totalpop['POPESTIMATE2021'] / N,\n",
    "        'POPESTIMATE2022': totalpop['POPESTIMATE2022'] / N,\n",
    "        'POPESTIMATE2023': totalpop['POPESTIMATE2023'] / N\n",
    "    })\n",
    "    popComplete.loc[len(popComplete)] = new_row\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### save completed dataset ###\n",
    "#  popComplete.to_csv('datasets/CountyPopulationAllYears.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll then have to redistribute the Mass Shootings and School incidents that occured in the counties that we've just eliminated."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing and data cleaning - Mass Shootings + School incidents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To clean the Gun Violence data we used Open Refine followed by python.\n",
    "#### Concatenating mass shootings csv\n",
    "The raw data from the Gun Violence Archaive is splitted into various datasets. To add everything into a same csv file, we simply used Open Refine and opened all the csv when starting a new project. This way, the multiple csv are automatiqually concatenated, as they all have the same columns. Before doing that, we had to eliminate some of the duplicate rows in the data, as the file `MassShootings_2021.csv` overlaps with the file `GunVioleceAllYears.csv`. Again, we used Open Refine to do so, by making a time facet of the file `MassShootings_2021.csv` and selectig the rows that were already in the `GunVioleceAllYears.csv` file, and then eliminating them.\n",
    "\n",
    "#### Tranformations\n",
    "We applied some basic transformations to the dataset, mainly just changing the types of some columns, such as *Incident Date* to date, and numerical columns into intiger. \n",
    "\n",
    "#### Obtaining counties with OSM\n",
    "To answer accuratelly the questions of the projecy, we needed the exact county where each incident occured. To obtain those, we first used Open Refine to obtain some json information from Open Street Maps, with the methos \"Add column by fetching URLs\". The command we used is:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "'https://nominatim.openstreetmap.org/search?format=json&email=pau.mateo.bernado@estudiantat.upc.edu&app=google-refine&q=' + \n",
    "escape(cells[\"City Or County\"].value + \", \" + cells[\"State\"].value, 'url') + '&limit=1&addressdetails =1'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this, we obtained some json information for each row, for example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[{\"place_id\":323075484,\n",
    "\"licence\":\"Data © OpenStreetMap contributors, ODbL 1.0. http://osm.org/copyright\",\n",
    "\"osm_type\":\"relation\",\n",
    "\"osm_id\":1180533,\n",
    "\"lat\":\"38.6280278\",\n",
    "\"lon\":\"-90.1910154\",\n",
    "\"class\":\"boundary\",\n",
    "\"type\":\"administrative\",\n",
    "\"place_rank\":12,\n",
    "\"importance\":0.7078550940195126,\n",
    "\"addresstype\":\"independent_city\",\n",
    "\"name\":\"Saint Louis\",\n",
    "\"display_name\":\"Saint Louis, Missouri, United States\",\n",
    "\"boundingbox\":[\"38.5323215\",\"38.7743018\",\"-90.3206525\",\"-90.1641941\"]}]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From this information we wantet to obtain the county for each incident. However, we weren't capable of doing so with Open Refine, as the URL used didn't return the names of the counties in the same format as the dataest form census.gov, so we had to process again this informatino with pytohn.\n",
    "We defined some functions that try to find a county name for each incident that exists in the population dataset obtained from census.gov. The functions iterate through the names in the key `\"display_name\"` from the json column (as there are some cases where the Township or some other information is also in the json code, so the county is not always in the same position) and applies some transformations to them and checks if the resulting name it's a county."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "from collections import defaultdict\n",
    "\n",
    "pop = pd.read_csv(\"datasets/CountyPopulationAllYears.csv\")\n",
    "\n",
    "names_counties = defaultdict(set)  # names of the counties for each state\n",
    "\n",
    "for state in pop['STNAME'].values:\n",
    "    names_counties[state] = set(pop[pop['STNAME']==state]['CTYNAME'].values)\n",
    "\n",
    "\n",
    "def transforms(name: str) -> str:\n",
    "    if 'Clarke' in name: return 'Clarke County'\n",
    "    if 'Washington' in name: return 'District of Columbia'\n",
    "    if 'Connecticut' in name: return 'connecticut_county_unknown'\n",
    "    name = name.replace('Saint', 'St.').replace('Nashville-', '').replace('Vista', 'Buena Vista').replace('Compton', 'Los Angeles County')\n",
    "    name = name.replace('Monterey Park', 'Monterey County')\n",
    "    return name.strip()\n",
    "\n",
    "\n",
    "def try_find(name, state) -> str | None:\n",
    "    '''tries to find the countie corresponding to `name` by \n",
    "    appliying transformations and trying diferent formats'''\n",
    "    if name in names_counties[state]: return name\n",
    "\n",
    "    if transforms(name) in names_counties[state]: return transforms(name)\n",
    "\n",
    "    #try county\n",
    "    n = transforms(name)\n",
    "    if 'County' not in n: n += ' County'\n",
    "    if n in names_counties[state]: return n\n",
    "\n",
    "    #try parish\n",
    "    n = transforms(name)\n",
    "    if 'Parish' not in n: n += ' Parish'\n",
    "    if n in names_counties[state]: return n\n",
    "\n",
    "    #try city\n",
    "    n = transforms(name)\n",
    "    if 'city' not in n: n += ' city'\n",
    "    if n in names_counties[state]: return n\n",
    "\n",
    "    #try Municipality\n",
    "    n = transforms(name)\n",
    "    if 'city' not in n: n += ' Municipality'\n",
    "    if n in names_counties[state]: return n\n",
    "    \n",
    "    else: return None\n",
    "\n",
    "\n",
    "def extract_county(row) -> str | None:\n",
    "    '''tries to extract the corresponding countie for the given row'''\n",
    "    json_data = row['json']\n",
    "    state = row['State'].strip()\n",
    "\n",
    "    places = json.loads(json_data)\n",
    "    if places:\n",
    "        names = places[0].get(\"display_name\", \"\")\n",
    "        # Cerca \"County\", \"Parish\", o altres entitats equivalents en display_name\n",
    "        \n",
    "        delims = [\",\", \")\", \"(\"]\n",
    "\n",
    "        for delim in delims:\n",
    "            names = \"_\".join(names.split(delim))\n",
    "        names = names.split(\"_\")\n",
    "        names = [n.strip() for n in names if n != '']\n",
    "\n",
    "        for n in names:\n",
    "            cname = try_find(n, state)\n",
    "            if cname: return cname\n",
    "            else: continue\n",
    "    \n",
    "        return None\n",
    "    \n",
    "\n",
    "SchoolIncidents = pd.read_csv('datasets/Schoolincidents-json.csv')\n",
    "MassShootingsComplete = pd.read_csv(\"datasets/MassShootingsComplete-json.csv\")\n",
    "\n",
    "MassShootingsComplete['county'] = MassShootingsComplete.apply(extract_county, axis=1)\n",
    "SchoolIncidents['county'] = SchoolIncidents.apply(extract_county, axis=1)\n",
    "\n",
    "#remove rows with null or unknown county\n",
    "MassShootingsComplete = MassShootingsComplete.dropna(subset=['county'])\n",
    "SchoolIncidents = SchoolIncidents.dropna(subset=['county'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this transformations we obtain a county for **all rows** that had a not null value in the json column (for 70 rows amongst 5k, the URLs from Open Refine extracted just `\"[]\"`)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obtaining FIPS codes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obtaining the FIPS codes for each county facilitated us working with altair's cloropleth charts. At this point, it was easy to obtain the FIPS codes for each incident, as we already had them in the County population csv. A simple function was enough:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import choice\n",
    "\n",
    "def get_fips(row) -> str | None:\n",
    "    \"\"\"\n",
    "    Returns the FIPS code for the given row by searching\n",
    "    it in the population csv\n",
    "    \"\"\"\n",
    "\n",
    "    county_value = row['county']\n",
    "\n",
    "    # connecticut separate case:\n",
    "    connecticut_fips = ['09110', '09120', '09130', '09140', '09150', '09160', '09170', '09180', '09190']\n",
    "    if county_value == 'connecticut_county_unknown':\n",
    "        fips = choice(connecticut_fips)  # we map the incident into a random county\n",
    "        return f'{int(fips):02d}'\n",
    "\n",
    "    if county_value is not None:\n",
    "        county_value = county_value.strip()\n",
    "    else:\n",
    "        county_value = \"\"  # Si és None, assignar una cadena buida per evitar errors\n",
    "    \n",
    "    fips_value = pop[(pop['STNAME'] == row['State']) & (pop['CTYNAME'] == county_value)]['FIPS']\n",
    "    \n",
    "    # Retornar el primer valor (ja que és únic)\n",
    "    return f'{fips_value.iloc[0]:02d}' if not fips_value.empty else None\n",
    "\n",
    "\n",
    "MassShootingsComplete['FIPS'] = MassShootingsComplete.apply(get_fips, axis=1)\n",
    "MassShootingsComplete['FIPS'] = MassShootingsComplete['FIPS'].apply(lambda x: f\"{int(x):05d}\") # to ensure length 5\n",
    "\n",
    "\n",
    "SchoolIncidents['FIPS'] = SchoolIncidents.apply(get_fips, axis=1)\n",
    "SchoolIncidents['FIPS'] = SchoolIncidents['FIPS'].apply(lambda x: f\"{int(x):05d}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The preprocessing is done! We are ready to start making visualizations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Q1**: What are the states with large number of mass shootings per citizen?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Q2:** How is the number of mass shootings per citizen distributed across the different counties in the US? And across states?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Q3:** Are the mass shootings correlated with gun violence incidents in schools?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Q4:** How have mass shootings evolved the last years in the US?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
